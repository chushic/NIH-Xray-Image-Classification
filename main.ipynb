{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a0dbe9a-9b1f-4e60-a3d7-fab1a9cf506f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06a1d742-6af5-4f62-b8e2-fd5e950aac36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os, pdb, sys, glob, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models \n",
    "\n",
    "from datasets import XRaysTrainDataset  \n",
    "from datasets import XRaysTestDataset\n",
    "\n",
    "# import neccesary libraries for defining the optimizers\n",
    "import torch.optim as optim\n",
    "\n",
    "from trainer import fit\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1e6b473-bea9-4d96-8c9a-2136fab071cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def q(text = ''): # easy way to exiting the script. useful while debugging\n",
    "    print('> ', text)\n",
    "    sys.exit()\n",
    "    \n",
    "def count_parameters(model): \n",
    "    num_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return num_parameters/1e6 # in terms of millions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b934acb-e54e-4dbd-9f1c-0e7377596749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations\n",
    "\n",
    "data_path = \"\"\n",
    "bs = 32 # batch size\n",
    "lr = 1e-5\n",
    "stage = 1\n",
    "loss_func = \"FocalLoss\"\n",
    "resume = False\n",
    "ckpt = \"\" # path to checkpoint\n",
    "test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c11ce1a-3892-4500-869d-05b27aa448c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# device diagnose\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bd71705-6f21-4ef0-85bb-c1d53d5afac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "data/Data_Entry_2017.csv found: True\n",
      "self.df.shape: (112120, 2)\n",
      "\n",
      "train_val_df.pickle: loaded\n",
      "self.train_val_df.shape: (86524, 2)\n",
      "\n",
      "Sampling the huuuge training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 86524/86524 [00:02<00:00, 32998.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "disease_classes.pickle: already exists\n",
      "\n",
      "self.all_classes_dict: {'Atelectasis': 7702, 'Infiltration': 10004, 'Cardiomegaly': 1633, 'Mass': 3828, 'No Finding': 10000, 'Effusion': 7978, 'Nodule': 4423, 'Pneumothorax': 2523, 'Edema': 1221, 'Fibrosis': 1187, 'Emphysema': 1368, 'Consolidation': 2657, 'Pneumonia': 797, 'Pleural_Thickening': 2129, 'Hernia': 141}\n",
      "\n",
      "self.df.shape: (112120, 2)\n",
      "\n",
      "test_df.pickle: loaded\n",
      "self.test_df.shape: (25596, 2)\n",
      "\n",
      "-----Initial Dataset Information-----\n",
      "num images in train_dataset   : 33790\n",
      "num images in val_dataset     : 8448\n",
      "num images in XRayTest_dataset: 25596\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "\n",
    "data_dir = os.path.join('data', data_path) # Data_Entry_2017.csv should be present in the mentioned path\n",
    "\n",
    "# define a function to count the total number of trainable parameters\n",
    "\n",
    "\n",
    "# make the datasets\n",
    "XRayTrain_dataset = XRaysTrainDataset(data_dir, transform = config.transform)\n",
    "train_percentage = 0.8\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(XRayTrain_dataset, [int(len(XRayTrain_dataset)*train_percentage), len(XRayTrain_dataset)-int(len(XRayTrain_dataset)*train_percentage)])\n",
    "\n",
    "XRayTest_dataset = XRaysTestDataset(data_dir, transform = config.transform)\n",
    "\n",
    "print('\\n-----Initial Dataset Information-----')\n",
    "print('num images in train_dataset   : {}'.format(len(train_dataset)))\n",
    "print('num images in val_dataset     : {}'.format(len(val_dataset)))\n",
    "print('num images in XRayTest_dataset: {}'.format(len(XRayTest_dataset)))\n",
    "print('-------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27f6433b-4dc7-4160-bb42-f31a937a0483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----Initial Batchloaders Information -----\n",
      "num batches in train_loader: 1056\n",
      "num batches in val_loader  : 264\n",
      "num batches in test_loader : 800\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# make the dataloaders\n",
    "batch_size = bs # 128 by default\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size, shuffle = not True)\n",
    "test_loader = torch.utils.data.DataLoader(XRayTest_dataset, batch_size = batch_size, shuffle = not True)\n",
    "\n",
    "print('\\n-----Initial Batchloaders Information -----')\n",
    "print('num batches in train_loader: {}'.format(len(train_loader)))\n",
    "print('num batches in val_loader  : {}'.format(len(val_loader)))\n",
    "print('num batches in test_loader : {}'.format(len(test_loader)))\n",
    "print('-------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cc91653-f745-4218-b434-4cd18edd4662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, model_name=\"unnmaed\", loss=\"FocalLoss\", epochs = 5, lr = 1e-5):\n",
    "    \n",
    "    print('TRAINING THE MODEL FROM SCRATCH')\n",
    "\n",
    "    script_start_time = time.time() # tells the total run time of this script\n",
    "\n",
    "    # sanity check\n",
    "    if len(XRayTrain_dataset.all_classes) != 15: # 15 is the unique number of diseases in this dataset\n",
    "        q('\\nnumber of classes not equal to 15 !')\n",
    "\n",
    "    a,b = train_dataset[0]\n",
    "    print(f'\\nwe are working with \\nImages shape: {a.shape} and \\nTarget shape: {b.shape}')\n",
    "\n",
    "    # make models directory, where the models and the loss plots will be saved\n",
    "    if not os.path.exists(config.models_dir):\n",
    "        os.mkdir(config.models_dir)\n",
    "\n",
    "    # define the loss function\n",
    "    if loss_func == 'FocalLoss': # by default\n",
    "        from losses import FocalLoss\n",
    "        loss_fn = FocalLoss(device = device, gamma = 2.).to(device)\n",
    "    elif loss_func == 'BCE':\n",
    "        loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "    print('\\ntraining from scratch')\n",
    "    # import pretrained model\n",
    "    # model = models.resnet50(pretrained=True) # pretrained = False bydefault\n",
    "    # change the last linear layer\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    # since we are not resuming the training of the model\n",
    "    epochs_till_now = 0\n",
    "\n",
    "    # making empty lists to collect all the losses\n",
    "    losses_dict = {'epoch_train_loss': [], 'epoch_val_loss': [], 'total_train_loss_list': [], 'total_val_loss_list': []}\n",
    "\n",
    "\n",
    "    # printing some hyperparameters\n",
    "    print('\\n> loss_fn: {}'.format(loss_fn))\n",
    "    print('> epochs_till_now: {}'.format(epochs_till_now))\n",
    "    print('> batch_size: {}'.format(batch_size))\n",
    "    print('> stage: {}'.format(stage))\n",
    "    print('> lr: {}'.format(lr))\n",
    "\n",
    "    for param in model.parameters(): # all requires_grad by default, are True initially\n",
    "        param.requires_grad = True\n",
    "\n",
    "\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr = lr)\n",
    "\n",
    "    # make changes in the parameters of the following 'fit' function\n",
    "    fit(device, XRayTrain_dataset, train_loader, val_loader,    \n",
    "                                            test_loader, model, model_name, loss_fn, \n",
    "                                            optimizer, losses_dict,\n",
    "                                            epochs_till_now = epochs_till_now, epochs = epochs,\n",
    "                                            log_interval = 25, save_interval = 1,\n",
    "                                            lr = lr, bs = batch_size,\n",
    "                                            test_only = False, )\n",
    "\n",
    "    script_time = time.time() - script_start_time\n",
    "    m, s = divmod(script_time, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    print(f'total running time: {int(h)} h {int(m)}m')\n",
    "\n",
    "def test_model(model_name, ckpt): # test = True, resume = False\n",
    "\n",
    "    losses_dict = {'epoch_train_loss': [], 'epoch_val_loss': [], 'total_train_loss_list': [], 'total_val_loss_list': []}\n",
    "    epochs_till_now = 0\n",
    "\n",
    "    script_start_time = time.time() # tells the total run time of this script\n",
    "\n",
    "    # sanity check\n",
    "    if len(XRayTrain_dataset.all_classes) != 15: # 15 is the unique number of diseases in this dataset\n",
    "        q('\\nnumber of classes not equal to 15 !')\n",
    "\n",
    "    a,b = train_dataset[0]\n",
    "    print('\\nwe are working with \\nImages shape: {} and \\nTarget shape: {}'.format( a.shape, b.shape))\n",
    "\n",
    "    # make models directory, where the models and the loss plots will be saved\n",
    "    if not os.path.exists(config.models_dir):\n",
    "        os.mkdir(config.models_dir)\n",
    "\n",
    "    # define the loss function\n",
    "    if loss_func == 'FocalLoss': # by default\n",
    "        from losses import FocalLoss\n",
    "        loss_fn = FocalLoss(device = device, gamma = 2.).to(device)\n",
    "    elif loss_func == 'BCE':\n",
    "        loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "    # testing\n",
    "    if ckpt == None:\n",
    "        q('ERROR: Please select a checkpoint to load the testing model from')\n",
    "\n",
    "    print('\\ncheckpoint loaded: {}'.format(ckpt))\n",
    "    ckpt = torch.load(os.path.join(config.models_dir, ckpt)) \n",
    "\n",
    "    # since we are resuming the training of the model\n",
    "    epochs_till_now = ckpt['epochs']\n",
    "    model = ckpt['model']\n",
    "    model.to(device)\n",
    "\n",
    "    # loading previous loss lists to collect future losses\n",
    "    losses_dict = ckpt['losses_dict']\n",
    "\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr = lr)\n",
    "\n",
    "    # make changes in the parameters of the following 'fit' function\n",
    "    fit(device, XRayTrain_dataset, train_loader, val_loader,    \n",
    "                                            test_loader, model, model_name, loss_fn, \n",
    "                                            optimizer, losses_dict,\n",
    "                                            epochs_till_now = epochs_till_now, epochs = 3,\n",
    "                                            log_interval = 25, save_interval = 1,\n",
    "                                            lr = lr, bs = batch_size,\n",
    "                                            test_only = True)\n",
    "\n",
    "    script_time = time.time() - script_start_time\n",
    "    m, s = divmod(script_time, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    print(f'total running time: {int(h)} h {int(m)}m')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cdf088-bafa-416d-9d44-d02d66e15a61",
   "metadata": {},
   "source": [
    "## resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "221dea7f-7de5-42d3-a6a8-3d7b8c71123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "num_ftrs = resnet50.fc.in_features\n",
    "resnet50.fc = nn.Linear(num_ftrs, len(XRayTrain_dataset.all_classes)) # 15 output classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df46b60e-79b5-4be4-99ef-5527bb8940ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(resnet50, \"resnet50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e887f8-009a-4ce0-8b03-e37cac3b77a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(ckpt=\"resnet50_1e-05_05.pth\")\n",
    "\n",
    "\n",
    "# we are working with \n",
    "# Images shape: torch.Size([3, 224, 224]) and \n",
    "# Target shape: torch.Size([15])\n",
    "\n",
    "# checkpoint loaded: resnet50_1e-05_05.pth\n",
    "\n",
    "# ======= Testing... =======\n",
    "\n",
    "# 400/400 (100.00 %)\n",
    "# NoFindingIndex:  10\n",
    "# y_true.shape, y_probs.shape  (25596, 15) (25596, 15)\n",
    "\n",
    "# class_roc_auc_list:  [0.715068159733321, 0.8317763860243287, 0.6807723553643712, 0.8192090286549367, 0.7875569096206302, 0.8586051173075546, 0.7716490627942258, 0.8370880548439736, 0.6483991160420525, 0.7230309983825862, 0.7076632816099293, 0.6843221061566516, 0.7107974986134953, 0.6627152371012439, 0.8176789116022511]\n",
    "\n",
    "# useful_classes_roc_auc_list [0.715068159733321, 0.8317763860243287, 0.6807723553643712, 0.8192090286549367, 0.7875569096206302, 0.8586051173075546, 0.7716490627942258, 0.8370880548439736, 0.6483991160420525, 0.7230309983825862, 0.6843221061566516, 0.7107974986134953, 0.6627152371012439, 0.8176789116022511]\n",
    "# test_roc_auc: 0.7534763530172588 in 9 mins 8 secs\n",
    "# total running time: 0 h 9m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773f3163-8451-45d9-84f8-3bd829245cce",
   "metadata": {},
   "source": [
    "## ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efebf60c-2a91-4a19-9d0c-23976f76f4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_base = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "num_ftrs = vit_base.heads.head.in_features\n",
    "vit_base.heads.head = nn.Linear(num_ftrs, len(XRayTrain_dataset.all_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cde32c58-bf40-4626-ae6b-fba0f8552cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING THE MODEL FROM SCRATCH\n",
      "\n",
      "we are working with \n",
      "Images shape: torch.Size([3, 224, 224]) and \n",
      "Target shape: torch.Size([15])\n",
      "\n",
      "training from scratch\n",
      "\n",
      "> loss_fn: FocalLoss()\n",
      "> epochs_till_now: 0\n",
      "> batch_size: 32\n",
      "> stage: 1\n",
      "> lr: 1e-05\n",
      "\n",
      "======= Training after epoch #0... =======\n",
      "\n",
      "============ EPOCH 1/5 ============\n",
      "TRAINING\n",
      "Train Loss for batch 025/1056 @epoch1/5: 0.06955 in 0 mins 2.11 secs\n",
      "Train Loss for batch 050/1056 @epoch1/5: 0.07365 in 0 mins 2.11 secs\n",
      "Train Loss for batch 075/1056 @epoch1/5: 0.06291 in 0 mins 2.16 secs\n",
      "Train Loss for batch 100/1056 @epoch1/5: 0.07791 in 0 mins 2.15 secs\n",
      "Train Loss for batch 125/1056 @epoch1/5: 0.08227 in 0 mins 2.14 secs\n",
      "Train Loss for batch 150/1056 @epoch1/5: 0.0734 in 0 mins 2.25 secs\n",
      "Train Loss for batch 175/1056 @epoch1/5: 0.06724 in 0 mins 2.11 secs\n",
      "Train Loss for batch 200/1056 @epoch1/5: 0.0689 in 0 mins 2.09 secs\n",
      "Train Loss for batch 225/1056 @epoch1/5: 0.05949 in 0 mins 2.14 secs\n",
      "Train Loss for batch 250/1056 @epoch1/5: 0.07222 in 0 mins 2.14 secs\n",
      "Train Loss for batch 275/1056 @epoch1/5: 0.06407 in 0 mins 2.12 secs\n",
      "Train Loss for batch 300/1056 @epoch1/5: 0.07329 in 0 mins 2.12 secs\n",
      "Train Loss for batch 325/1056 @epoch1/5: 0.06167 in 0 mins 2.13 secs\n",
      "Train Loss for batch 350/1056 @epoch1/5: 0.07102 in 0 mins 2.17 secs\n",
      "Train Loss for batch 375/1056 @epoch1/5: 0.07108 in 0 mins 2.12 secs\n",
      "Train Loss for batch 400/1056 @epoch1/5: 0.06403 in 0 mins 2.12 secs\n",
      "Train Loss for batch 425/1056 @epoch1/5: 0.06487 in 0 mins 2.19 secs\n",
      "Train Loss for batch 450/1056 @epoch1/5: 0.0674 in 0 mins 2.16 secs\n",
      "Train Loss for batch 475/1056 @epoch1/5: 0.0664 in 0 mins 2.14 secs\n",
      "Train Loss for batch 500/1056 @epoch1/5: 0.07465 in 0 mins 2.24 secs\n",
      "Train Loss for batch 525/1056 @epoch1/5: 0.07536 in 0 mins 4.92 secs\n",
      "Train Loss for batch 550/1056 @epoch1/5: 0.07431 in 0 mins 2.1 secs\n",
      "Train Loss for batch 575/1056 @epoch1/5: 0.0711 in 0 mins 2.1 secs\n",
      "Train Loss for batch 600/1056 @epoch1/5: 0.06927 in 0 mins 2.12 secs\n",
      "Train Loss for batch 625/1056 @epoch1/5: 0.0727 in 0 mins 2.21 secs\n",
      "Train Loss for batch 650/1056 @epoch1/5: 0.0656 in 0 mins 2.16 secs\n",
      "Train Loss for batch 675/1056 @epoch1/5: 0.05689 in 0 mins 2.19 secs\n",
      "Train Loss for batch 700/1056 @epoch1/5: 0.06547 in 0 mins 2.21 secs\n",
      "Train Loss for batch 725/1056 @epoch1/5: 0.07519 in 0 mins 2.11 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for batch 750/1056 @epoch1/5: 0.0556 in 0 mins 2.1 secs\n",
      "Train Loss for batch 775/1056 @epoch1/5: 0.06176 in 0 mins 2.31 secs\n",
      "Train Loss for batch 800/1056 @epoch1/5: 0.05982 in 0 mins 2.1 secs\n",
      "Train Loss for batch 825/1056 @epoch1/5: 0.06278 in 0 mins 2.1 secs\n",
      "Train Loss for batch 850/1056 @epoch1/5: 0.06544 in 0 mins 2.1 secs\n",
      "Train Loss for batch 875/1056 @epoch1/5: 0.05748 in 0 mins 2.1 secs\n",
      "Train Loss for batch 900/1056 @epoch1/5: 0.06402 in 0 mins 2.15 secs\n",
      "Train Loss for batch 925/1056 @epoch1/5: 0.06282 in 0 mins 2.1 secs\n",
      "Train Loss for batch 950/1056 @epoch1/5: 0.05648 in 0 mins 2.17 secs\n",
      "Train Loss for batch 975/1056 @epoch1/5: 0.05841 in 0 mins 2.12 secs\n",
      "Train Loss for batch 1000/1056 @epoch1/5: 0.06655 in 0 mins 2.16 secs\n",
      "Train Loss for batch 1025/1056 @epoch1/5: 0.06637 in 0 mins 2.16 secs\n",
      "Train Loss for batch 1050/1056 @epoch1/5: 0.05704 in 0 mins 2.27 secs\n",
      "VALIDATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss   for batch 025/264 @epoch1/5: 0.06762 in 0 mins 1.1 secs\n",
      "Val Loss   for batch 050/264 @epoch1/5: 0.05624 in 0 mins 1.14 secs\n",
      "Val Loss   for batch 075/264 @epoch1/5: 0.0571 in 0 mins 1.12 secs\n",
      "Val Loss   for batch 100/264 @epoch1/5: 0.05797 in 0 mins 1.13 secs\n",
      "Val Loss   for batch 125/264 @epoch1/5: 0.06125 in 0 mins 1.13 secs\n",
      "Val Loss   for batch 150/264 @epoch1/5: 0.06351 in 0 mins 1.12 secs\n",
      "Val Loss   for batch 175/264 @epoch1/5: 0.07386 in 0 mins 1.09 secs\n",
      "Val Loss   for batch 200/264 @epoch1/5: 0.05963 in 0 mins 1.12 secs\n",
      "Val Loss   for batch 225/264 @epoch1/5: 0.07046 in 0 mins 1.1 secs\n",
      "Val Loss   for batch 250/264 @epoch1/5: 0.0702 in 0 mins 1.16 secs\n",
      "\n",
      "NoFindingIndex:  10\n",
      "y_true.shape, y_probs.shape  (8448, 15) (8448, 15)\n",
      "\n",
      "class_roc_auc_list:  [0.7612283103469777, 0.8778066084620451, 0.7126378197362818, 0.8491325212255444, 0.8277837148594757, 0.7930051156406652, 0.7417160685062604, 0.7879520360916539, 0.6442228712433438, 0.732507276849407, 0.7466348074004436, 0.6848947003159049, 0.7071697521888951, 0.6581770588431306, 0.7680818111285812]\n",
      "\n",
      "useful_classes_roc_auc_list [0.7612283103469777, 0.8778066084620451, 0.7126378197362818, 0.8491325212255444, 0.8277837148594757, 0.7930051156406652, 0.7417160685062604, 0.7879520360916539, 0.6442228712433438, 0.732507276849407, 0.6848947003159049, 0.7071697521888951, 0.6581770588431306, 0.7680818111285812]\n",
      "\n",
      "checkpoint models/vit_base_1e-05_01.pth saved\n",
      "loss plots saved !!!\n",
      "\n",
      "TRAIN LOSS : 0.0668240934729435\n",
      "VAL   LOSS : 0.06456875061672745\n",
      "VAL ROC_AUC: 0.753308261817012\n",
      "\n",
      "Epoch 1/5 took 0 h 43 m\n",
      "\n",
      "Sampling the huuuge training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 86524/86524 [00:02<00:00, 32012.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "self.all_classes_dict: {'Effusion': 7996, 'No Finding': 10000, 'Atelectasis': 7700, 'Infiltration': 10007, 'Edema': 1213, 'Consolidation': 2685, 'Nodule': 4422, 'Mass': 3846, 'Pneumothorax': 2518, 'Pneumonia': 779, 'Pleural_Thickening': 2125, 'Fibrosis': 1182, 'Cardiomegaly': 1627, 'Emphysema': 1354, 'Hernia': 141}\n",
      "\n",
      "-----Resampled Dataset Information-----\n",
      "num images in train_dataset   : 33794\n",
      "num images in val_dataset     : 8449\n",
      "---------------------------------------\n",
      "\n",
      "-----Resampled Batchloaders Information -----\n",
      "num batches in train_loader: 1057\n",
      "num batches in val_loader  : 265\n",
      "---------------------------------------------\n",
      "\n",
      "============ EPOCH 2/5 ============\n",
      "TRAINING\n",
      "Train Loss for batch 025/1057 @epoch2/5: 0.05298 in 0 mins 6.3 secs\n",
      "Train Loss for batch 050/1057 @epoch2/5: 0.06296 in 0 mins 2.28 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for batch 075/1057 @epoch2/5: 0.06147 in 0 mins 2.17 secs\n",
      "Train Loss for batch 100/1057 @epoch2/5: 0.06346 in 0 mins 2.25 secs\n",
      "Train Loss for batch 125/1057 @epoch2/5: 0.07509 in 0 mins 2.11 secs\n",
      "Train Loss for batch 150/1057 @epoch2/5: 0.06877 in 0 mins 2.24 secs\n",
      "Train Loss for batch 175/1057 @epoch2/5: 0.06881 in 0 mins 2.12 secs\n",
      "Train Loss for batch 200/1057 @epoch2/5: 0.06832 in 0 mins 2.11 secs\n",
      "Train Loss for batch 225/1057 @epoch2/5: 0.07287 in 0 mins 2.08 secs\n",
      "Train Loss for batch 250/1057 @epoch2/5: 0.05551 in 0 mins 2.36 secs\n",
      "Train Loss for batch 275/1057 @epoch2/5: 0.07896 in 0 mins 2.24 secs\n",
      "Train Loss for batch 300/1057 @epoch2/5: 0.07051 in 0 mins 2.24 secs\n",
      "Train Loss for batch 325/1057 @epoch2/5: 0.07286 in 0 mins 2.15 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for batch 350/1057 @epoch2/5: 0.07099 in 0 mins 2.2 secs\n",
      "Train Loss for batch 375/1057 @epoch2/5: 0.05838 in 0 mins 2.29 secs\n",
      "Train Loss for batch 400/1057 @epoch2/5: 0.05197 in 0 mins 2.13 secs\n",
      "Train Loss for batch 425/1057 @epoch2/5: 0.05993 in 0 mins 2.1 secs\n",
      "Train Loss for batch 450/1057 @epoch2/5: 0.05634 in 0 mins 2.19 secs\n",
      "Train Loss for batch 475/1057 @epoch2/5: 0.06981 in 0 mins 2.11 secs\n",
      "Train Loss for batch 500/1057 @epoch2/5: 0.05464 in 0 mins 2.15 secs\n",
      "Train Loss for batch 525/1057 @epoch2/5: 0.06736 in 0 mins 2.1 secs\n",
      "Train Loss for batch 550/1057 @epoch2/5: 0.05671 in 0 mins 2.2 secs\n",
      "Train Loss for batch 575/1057 @epoch2/5: 0.06992 in 0 mins 2.11 secs\n",
      "Train Loss for batch 600/1057 @epoch2/5: 0.05992 in 0 mins 2.13 secs\n",
      "Train Loss for batch 625/1057 @epoch2/5: 0.05246 in 0 mins 2.12 secs\n",
      "Train Loss for batch 650/1057 @epoch2/5: 0.06864 in 0 mins 2.12 secs\n",
      "Train Loss for batch 675/1057 @epoch2/5: 0.06475 in 0 mins 2.21 secs\n",
      "Train Loss for batch 700/1057 @epoch2/5: 0.06547 in 0 mins 6.53 secs\n",
      "Train Loss for batch 725/1057 @epoch2/5: 0.06326 in 0 mins 2.29 secs\n",
      "Train Loss for batch 750/1057 @epoch2/5: 0.06695 in 0 mins 2.24 secs\n",
      "Train Loss for batch 775/1057 @epoch2/5: 0.06421 in 0 mins 2.21 secs\n",
      "Train Loss for batch 800/1057 @epoch2/5: 0.06449 in 0 mins 2.2 secs\n",
      "Train Loss for batch 825/1057 @epoch2/5: 0.05727 in 0 mins 2.12 secs\n",
      "Train Loss for batch 850/1057 @epoch2/5: 0.05851 in 0 mins 2.2 secs\n",
      "Train Loss for batch 875/1057 @epoch2/5: 0.05462 in 0 mins 2.22 secs\n",
      "Train Loss for batch 900/1057 @epoch2/5: 0.05315 in 0 mins 2.1 secs\n",
      "Train Loss for batch 925/1057 @epoch2/5: 0.07044 in 0 mins 2.1 secs\n",
      "Train Loss for batch 950/1057 @epoch2/5: 0.06823 in 0 mins 2.1 secs\n",
      "Train Loss for batch 975/1057 @epoch2/5: 0.06298 in 0 mins 2.57 secs\n",
      "Train Loss for batch 1000/1057 @epoch2/5: 0.06224 in 0 mins 6.75 secs\n",
      "Train Loss for batch 1025/1057 @epoch2/5: 0.05634 in 0 mins 2.15 secs\n",
      "Train Loss for batch 1050/1057 @epoch2/5: 0.05623 in 0 mins 3.07 secs\n",
      "VALIDATION\n",
      "Val Loss   for batch 025/265 @epoch2/5: 0.06023 in 0 mins 1.15 secs\n",
      "Val Loss   for batch 050/265 @epoch2/5: 0.06665 in 0 mins 1.12 secs\n",
      "Val Loss   for batch 075/265 @epoch2/5: 0.05541 in 0 mins 1.12 secs\n",
      "Val Loss   for batch 100/265 @epoch2/5: 0.06707 in 0 mins 1.36 secs\n",
      "Val Loss   for batch 125/265 @epoch2/5: 0.06403 in 0 mins 1.7 secs\n",
      "Val Loss   for batch 150/265 @epoch2/5: 0.07017 in 0 mins 1.88 secs\n",
      "Val Loss   for batch 175/265 @epoch2/5: 0.05427 in 0 mins 1.14 secs\n",
      "Val Loss   for batch 200/265 @epoch2/5: 0.0635 in 0 mins 1.22 secs\n",
      "Val Loss   for batch 225/265 @epoch2/5: 0.0593 in 0 mins 1.16 secs\n",
      "Val Loss   for batch 250/265 @epoch2/5: 0.05661 in 0 mins 2.07 secs\n",
      "\n",
      "NoFindingIndex:  10\n",
      "y_true.shape, y_probs.shape  (8449, 15) (8449, 15)\n",
      "\n",
      "class_roc_auc_list:  [0.7705685654967307, 0.8997450245421432, 0.7431618249465923, 0.876081352821302, 0.8492805956296715, 0.8251934133427908, 0.7138447222559371, 0.798804291879479, 0.6666426652453507, 0.7646789746693906, 0.7542924803512336, 0.7013438368860055, 0.7202917098327478, 0.6466109341994253, 0.7835692480162975]\n",
      "\n",
      "useful_classes_roc_auc_list [0.7705685654967307, 0.8997450245421432, 0.7431618249465923, 0.876081352821302, 0.8492805956296715, 0.8251934133427908, 0.7138447222559371, 0.798804291879479, 0.6666426652453507, 0.7646789746693906, 0.7013438368860055, 0.7202917098327478, 0.6466109341994253, 0.7835692480162975]\n",
      "\n",
      "checkpoint models/vit_base_1e-05_02.pth saved\n",
      "loss plots saved !!!\n",
      "\n",
      "TRAIN LOSS : 0.06325134010158177\n",
      "VAL   LOSS : 0.06198777273475439\n",
      "VAL ROC_AUC: 0.7685583685545617\n",
      "\n",
      "Epoch 2/5 took 1 h 50 m\n",
      "\n",
      "Sampling the huuuge training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 86524/86524 [00:02<00:00, 33754.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "self.all_classes_dict: {'Infiltration': 10007, 'Mass': 3835, 'No Finding': 10000, 'Atelectasis': 7702, 'Nodule': 4431, 'Cardiomegaly': 1626, 'Consolidation': 2663, 'Fibrosis': 1170, 'Effusion': 7991, 'Pneumothorax': 2523, 'Emphysema': 1356, 'Edema': 1211, 'Pneumonia': 794, 'Pleural_Thickening': 2115, 'Hernia': 141}\n",
      "\n",
      "-----Resampled Dataset Information-----\n",
      "num images in train_dataset   : 33792\n",
      "num images in val_dataset     : 8449\n",
      "---------------------------------------\n",
      "\n",
      "-----Resampled Batchloaders Information -----\n",
      "num batches in train_loader: 1056\n",
      "num batches in val_loader  : 265\n",
      "---------------------------------------------\n",
      "\n",
      "============ EPOCH 3/5 ============\n",
      "TRAINING\n",
      "Train Loss for batch 025/1056 @epoch3/5: 0.06015 in 0 mins 2.15 secs\n",
      "Train Loss for batch 050/1056 @epoch3/5: 0.06859 in 0 mins 2.2 secs\n",
      "Train Loss for batch 075/1056 @epoch3/5: 0.0583 in 0 mins 3.24 secs\n",
      "Train Loss for batch 100/1056 @epoch3/5: 0.06603 in 0 mins 2.15 secs\n",
      "Train Loss for batch 125/1056 @epoch3/5: 0.06668 in 0 mins 3.0 secs\n",
      "Train Loss for batch 150/1056 @epoch3/5: 0.05552 in 0 mins 2.12 secs\n",
      "Train Loss for batch 175/1056 @epoch3/5: 0.06311 in 0 mins 2.17 secs\n",
      "Train Loss for batch 200/1056 @epoch3/5: 0.05416 in 3 mins 26.46 secs\n",
      "Train Loss for batch 225/1056 @epoch3/5: 0.06044 in 0 mins 2.28 secs\n",
      "Train Loss for batch 250/1056 @epoch3/5: 0.06081 in 0 mins 2.84 secs\n",
      "Train Loss for batch 275/1056 @epoch3/5: 0.05469 in 0 mins 2.13 secs\n",
      "Train Loss for batch 300/1056 @epoch3/5: 0.06014 in 0 mins 2.12 secs\n",
      "Train Loss for batch 325/1056 @epoch3/5: 0.07183 in 0 mins 2.12 secs\n",
      "Train Loss for batch 350/1056 @epoch3/5: 0.06623 in 0 mins 2.12 secs\n",
      "Train Loss for batch 375/1056 @epoch3/5: 0.05218 in 0 mins 2.15 secs\n",
      "Train Loss for batch 400/1056 @epoch3/5: 0.04851 in 0 mins 2.12 secs\n",
      "Train Loss for batch 425/1056 @epoch3/5: 0.06083 in 0 mins 2.1 secs\n",
      "Train Loss for batch 450/1056 @epoch3/5: 0.06065 in 0 mins 2.11 secs\n",
      "Train Loss for batch 475/1056 @epoch3/5: 0.06147 in 0 mins 2.11 secs\n",
      "Train Loss for batch 500/1056 @epoch3/5: 0.0636 in 0 mins 2.14 secs\n",
      "Train Loss for batch 525/1056 @epoch3/5: 0.04945 in 0 mins 2.33 secs\n",
      "Train Loss for batch 550/1056 @epoch3/5: 0.06097 in 0 mins 2.13 secs\n",
      "Train Loss for batch 575/1056 @epoch3/5: 0.06289 in 0 mins 2.13 secs\n",
      "Train Loss for batch 600/1056 @epoch3/5: 0.05947 in 0 mins 2.12 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for batch 625/1056 @epoch3/5: 0.05355 in 0 mins 2.14 secs\n",
      "Train Loss for batch 650/1056 @epoch3/5: 0.0569 in 0 mins 2.11 secs\n",
      "Train Loss for batch 675/1056 @epoch3/5: 0.06011 in 0 mins 2.16 secs\n",
      "Train Loss for batch 700/1056 @epoch3/5: 0.0719 in 0 mins 2.1 secs\n",
      "Train Loss for batch 725/1056 @epoch3/5: 0.05848 in 0 mins 2.13 secs\n",
      "Train Loss for batch 750/1056 @epoch3/5: 0.05761 in 0 mins 2.18 secs\n",
      "Train Loss for batch 775/1056 @epoch3/5: 0.05976 in 0 mins 2.43 secs\n",
      "Train Loss for batch 800/1056 @epoch3/5: 0.06143 in 0 mins 2.17 secs\n",
      "Train Loss for batch 825/1056 @epoch3/5: 0.05618 in 0 mins 2.1 secs\n",
      "Train Loss for batch 850/1056 @epoch3/5: 0.05081 in 0 mins 2.12 secs\n",
      "Train Loss for batch 875/1056 @epoch3/5: 0.06083 in 0 mins 2.11 secs\n",
      "Train Loss for batch 900/1056 @epoch3/5: 0.06088 in 0 mins 2.11 secs\n",
      "Train Loss for batch 925/1056 @epoch3/5: 0.06876 in 0 mins 2.16 secs\n",
      "Train Loss for batch 950/1056 @epoch3/5: 0.04972 in 0 mins 2.13 secs\n",
      "Train Loss for batch 975/1056 @epoch3/5: 0.06432 in 0 mins 2.15 secs\n",
      "Train Loss for batch 1000/1056 @epoch3/5: 0.0537 in 0 mins 2.11 secs\n",
      "Train Loss for batch 1025/1056 @epoch3/5: 0.07102 in 0 mins 2.11 secs\n",
      "Train Loss for batch 1050/1056 @epoch3/5: 0.05425 in 0 mins 2.16 secs\n",
      "VALIDATION\n",
      "Val Loss   for batch 025/265 @epoch3/5: 0.05022 in 0 mins 1.12 secs\n",
      "Val Loss   for batch 050/265 @epoch3/5: 0.05801 in 0 mins 1.25 secs\n",
      "Val Loss   for batch 075/265 @epoch3/5: 0.05526 in 0 mins 1.13 secs\n",
      "Val Loss   for batch 100/265 @epoch3/5: 0.07071 in 0 mins 1.1 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss   for batch 125/265 @epoch3/5: 0.06772 in 0 mins 1.11 secs\n",
      "Val Loss   for batch 150/265 @epoch3/5: 0.06052 in 0 mins 1.1 secs\n",
      "Val Loss   for batch 175/265 @epoch3/5: 0.06136 in 0 mins 1.12 secs\n",
      "Val Loss   for batch 200/265 @epoch3/5: 0.06545 in 0 mins 1.1 secs\n",
      "Val Loss   for batch 225/265 @epoch3/5: 0.06015 in 0 mins 1.11 secs\n",
      "Val Loss   for batch 250/265 @epoch3/5: 0.05794 in 0 mins 1.14 secs\n",
      "\n",
      "NoFindingIndex:  10\n",
      "y_true.shape, y_probs.shape  (8449, 15) (8449, 15)\n",
      "\n",
      "class_roc_auc_list:  [0.7774063462644777, 0.9125281255559055, 0.7515237217724512, 0.8835762514891622, 0.8495399319780697, 0.8456499213786458, 0.7866543369131064, 0.7585428782046032, 0.667442430793746, 0.794789530403258, 0.754283905654369, 0.7270713477248603, 0.736474807239941, 0.6996622310630083, 0.8011934684367993]\n",
      "\n",
      "useful_classes_roc_auc_list [0.7774063462644777, 0.9125281255559055, 0.7515237217724512, 0.8835762514891622, 0.8495399319780697, 0.8456499213786458, 0.7866543369131064, 0.7585428782046032, 0.667442430793746, 0.794789530403258, 0.7270713477248603, 0.736474807239941, 0.6996622310630083, 0.8011934684367993]\n",
      "\n",
      "checkpoint models/vit_base_1e-05_03.pth saved\n",
      "loss plots saved !!!\n",
      "\n",
      "TRAIN LOSS : 0.06149601140835633\n",
      "VAL   LOSS : 0.061737674186490094\n",
      "VAL ROC_AUC: 0.7851468092298598\n",
      "\n",
      "Epoch 3/5 took 2 h 6 m\n",
      "\n",
      "Sampling the huuuge training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 86524/86524 [00:02<00:00, 33764.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "self.all_classes_dict: {'No Finding': 10000, 'Nodule': 4399, 'Infiltration': 10004, 'Mass': 3820, 'Pleural_Thickening': 2125, 'Cardiomegaly': 1639, 'Atelectasis': 7702, 'Pneumothorax': 2514, 'Effusion': 7997, 'Consolidation': 2665, 'Hernia': 141, 'Emphysema': 1360, 'Pneumonia': 779, 'Fibrosis': 1199, 'Edema': 1211}\n",
      "\n",
      "-----Resampled Dataset Information-----\n",
      "num images in train_dataset   : 33790\n",
      "num images in val_dataset     : 8448\n",
      "---------------------------------------\n",
      "\n",
      "-----Resampled Batchloaders Information -----\n",
      "num batches in train_loader: 1056\n",
      "num batches in val_loader  : 264\n",
      "---------------------------------------------\n",
      "\n",
      "============ EPOCH 4/5 ============\n",
      "TRAINING\n",
      "Train Loss for batch 025/1056 @epoch4/5: 0.05756 in 0 mins 2.22 secs\n",
      "Train Loss for batch 050/1056 @epoch4/5: 0.06506 in 0 mins 2.1 secs\n",
      "Train Loss for batch 075/1056 @epoch4/5: 0.05234 in 0 mins 2.13 secs\n",
      "Train Loss for batch 100/1056 @epoch4/5: 0.05795 in 0 mins 2.13 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for batch 125/1056 @epoch4/5: 0.05906 in 0 mins 2.1 secs\n",
      "Train Loss for batch 150/1056 @epoch4/5: 0.04793 in 0 mins 2.14 secs\n",
      "Train Loss for batch 175/1056 @epoch4/5: 0.05667 in 0 mins 2.1 secs\n",
      "Train Loss for batch 200/1056 @epoch4/5: 0.06226 in 0 mins 2.13 secs\n",
      "Train Loss for batch 225/1056 @epoch4/5: 0.06428 in 0 mins 2.19 secs\n",
      "Train Loss for batch 250/1056 @epoch4/5: 0.05358 in 0 mins 2.11 secs\n",
      "Train Loss for batch 275/1056 @epoch4/5: 0.07202 in 0 mins 2.15 secs\n",
      "Train Loss for batch 300/1056 @epoch4/5: 0.06527 in 0 mins 2.11 secs\n",
      "Train Loss for batch 325/1056 @epoch4/5: 0.06785 in 0 mins 2.11 secs\n",
      "Train Loss for batch 350/1056 @epoch4/5: 0.05737 in 0 mins 2.13 secs\n",
      "Train Loss for batch 375/1056 @epoch4/5: 0.06216 in 0 mins 2.13 secs\n",
      "Train Loss for batch 400/1056 @epoch4/5: 0.06055 in 0 mins 2.13 secs\n",
      "Train Loss for batch 425/1056 @epoch4/5: 0.06776 in 0 mins 2.11 secs\n",
      "Train Loss for batch 450/1056 @epoch4/5: 0.06096 in 0 mins 2.11 secs\n",
      "Train Loss for batch 475/1056 @epoch4/5: 0.0585 in 0 mins 2.11 secs\n",
      "Train Loss for batch 500/1056 @epoch4/5: 0.04616 in 0 mins 2.32 secs\n",
      "Train Loss for batch 525/1056 @epoch4/5: 0.05503 in 0 mins 2.13 secs\n",
      "Train Loss for batch 550/1056 @epoch4/5: 0.0635 in 0 mins 2.15 secs\n",
      "Train Loss for batch 575/1056 @epoch4/5: 0.06077 in 0 mins 2.1 secs\n",
      "Train Loss for batch 600/1056 @epoch4/5: 0.06 in 0 mins 2.12 secs\n",
      "Train Loss for batch 625/1056 @epoch4/5: 0.06166 in 0 mins 2.12 secs\n",
      "Train Loss for batch 650/1056 @epoch4/5: 0.06068 in 0 mins 2.17 secs\n",
      "Train Loss for batch 675/1056 @epoch4/5: 0.06388 in 0 mins 2.13 secs\n",
      "Train Loss for batch 700/1056 @epoch4/5: 0.05911 in 0 mins 2.11 secs\n",
      "Train Loss for batch 725/1056 @epoch4/5: 0.06203 in 0 mins 2.18 secs\n",
      "Train Loss for batch 750/1056 @epoch4/5: 0.0685 in 0 mins 2.11 secs\n",
      "Train Loss for batch 775/1056 @epoch4/5: 0.06005 in 0 mins 2.16 secs\n",
      "Train Loss for batch 800/1056 @epoch4/5: 0.0601 in 0 mins 2.13 secs\n",
      "Train Loss for batch 825/1056 @epoch4/5: 0.06168 in 0 mins 2.12 secs\n",
      "Train Loss for batch 850/1056 @epoch4/5: 0.06371 in 0 mins 2.12 secs\n",
      "Train Loss for batch 875/1056 @epoch4/5: 0.05416 in 0 mins 2.23 secs\n",
      "Train Loss for batch 900/1056 @epoch4/5: 0.05731 in 0 mins 2.18 secs\n",
      "Train Loss for batch 925/1056 @epoch4/5: 0.05525 in 0 mins 2.1 secs\n",
      "Train Loss for batch 950/1056 @epoch4/5: 0.06344 in 0 mins 2.85 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for batch 975/1056 @epoch4/5: 0.06673 in 8 mins 33.67 secs\n",
      "Train Loss for batch 1000/1056 @epoch4/5: 0.061 in 0 mins 2.13 secs\n",
      "Train Loss for batch 1025/1056 @epoch4/5: 0.06035 in 0 mins 2.45 secs\n",
      "Train Loss for batch 1050/1056 @epoch4/5: 0.06674 in 0 mins 3.15 secs\n",
      "VALIDATION\n",
      "Val Loss   for batch 025/264 @epoch4/5: 0.06183 in 16 mins 47.26 secs\n",
      "Val Loss   for batch 050/264 @epoch4/5: 0.05778 in 0 mins 1.12 secs\n",
      "Val Loss   for batch 075/264 @epoch4/5: 0.05825 in 0 mins 1.12 secs\n",
      "Val Loss   for batch 100/264 @epoch4/5: 0.0587 in 0 mins 1.15 secs\n",
      "Val Loss   for batch 125/264 @epoch4/5: 0.05946 in 0 mins 1.31 secs\n",
      "Val Loss   for batch 150/264 @epoch4/5: 0.0558 in 0 mins 1.38 secs\n",
      "Val Loss   for batch 175/264 @epoch4/5: 0.0617 in 0 mins 1.47 secs\n",
      "Val Loss   for batch 200/264 @epoch4/5: 0.05486 in 0 mins 1.57 secs\n",
      "Val Loss   for batch 225/264 @epoch4/5: 0.05517 in 0 mins 1.64 secs\n",
      "Val Loss   for batch 250/264 @epoch4/5: 0.06374 in 0 mins 1.68 secs\n",
      "\n",
      "NoFindingIndex:  10\n",
      "y_true.shape, y_probs.shape  (8448, 15) (8448, 15)\n",
      "\n",
      "class_roc_auc_list:  [0.7858281040074406, 0.913767522541561, 0.7486988039895419, 0.8864192163748641, 0.8441988403862084, 0.8706659047822289, 0.7798148823759916, 0.8600441126569393, 0.6817284522350104, 0.831368564433066, 0.7712213089330026, 0.7347740877640051, 0.7603993572391818, 0.7027997874748781, 0.8208929146333035]\n",
      "\n",
      "useful_classes_roc_auc_list [0.7858281040074406, 0.913767522541561, 0.7486988039895419, 0.8864192163748641, 0.8441988403862084, 0.8706659047822289, 0.7798148823759916, 0.8600441126569393, 0.6817284522350104, 0.831368564433066, 0.7347740877640051, 0.7603993572391818, 0.7027997874748781, 0.8208929146333035]\n",
      "\n",
      "checkpoint models/vit_base_1e-05_04.pth saved\n",
      "loss plots saved !!!\n",
      "\n",
      "TRAIN LOSS : 0.060149115592364764\n",
      "VAL   LOSS : 0.05979348115171447\n",
      "VAL ROC_AUC: 0.8015286107781587\n",
      "\n",
      "Epoch 4/5 took 2 h 23 m\n",
      "\n",
      "Sampling the huuuge training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 86524/86524 [00:02<00:00, 33115.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "self.all_classes_dict: {'Consolidation': 2658, 'No Finding': 10000, 'Effusion': 8014, 'Emphysema': 1367, 'Infiltration': 10008, 'Mass': 3813, 'Pneumothorax': 2529, 'Edema': 1189, 'Atelectasis': 7700, 'Pneumonia': 779, 'Pleural_Thickening': 2122, 'Cardiomegaly': 1632, 'Fibrosis': 1168, 'Nodule': 4436, 'Hernia': 141}\n",
      "\n",
      "-----Resampled Dataset Information-----\n",
      "num images in train_dataset   : 33796\n",
      "num images in val_dataset     : 8449\n",
      "---------------------------------------\n",
      "\n",
      "-----Resampled Batchloaders Information -----\n",
      "num batches in train_loader: 1057\n",
      "num batches in val_loader  : 265\n",
      "---------------------------------------------\n",
      "\n",
      "============ EPOCH 5/5 ============\n",
      "TRAINING\n",
      "Train Loss for batch 025/1057 @epoch5/5: 0.0593 in 0 mins 3.68 secs\n",
      "Train Loss for batch 050/1057 @epoch5/5: 0.05565 in 0 mins 3.65 secs\n",
      "Train Loss for batch 075/1057 @epoch5/5: 0.07191 in 0 mins 4.21 secs\n",
      "Train Loss for batch 100/1057 @epoch5/5: 0.0596 in 0 mins 4.65 secs\n",
      "Train Loss for batch 125/1057 @epoch5/5: 0.05753 in 0 mins 4.75 secs\n",
      "Train Loss for batch 150/1057 @epoch5/5: 0.05399 in 0 mins 4.31 secs\n",
      "Train Loss for batch 175/1057 @epoch5/5: 0.05322 in 0 mins 4.47 secs\n",
      "Train Loss for batch 200/1057 @epoch5/5: 0.05397 in 0 mins 4.01 secs\n",
      "Train Loss for batch 225/1057 @epoch5/5: 0.06474 in 0 mins 8.13 secs\n",
      "Train Loss for batch 250/1057 @epoch5/5: 0.05426 in 0 mins 4.29 secs\n",
      "Train Loss for batch 275/1057 @epoch5/5: 0.05464 in 0 mins 4.37 secs\n",
      "Train Loss for batch 300/1057 @epoch5/5: 0.05888 in 0 mins 3.54 secs\n",
      "Train Loss for batch 325/1057 @epoch5/5: 0.05661 in 0 mins 4.04 secs\n",
      "Train Loss for batch 350/1057 @epoch5/5: 0.06369 in 0 mins 4.28 secs\n",
      "Train Loss for batch 375/1057 @epoch5/5: 0.06799 in 0 mins 4.8 secs\n",
      "Train Loss for batch 400/1057 @epoch5/5: 0.06461 in 0 mins 2.13 secs\n",
      "Train Loss for batch 425/1057 @epoch5/5: 0.0504 in 0 mins 2.12 secs\n",
      "Train Loss for batch 450/1057 @epoch5/5: 0.06385 in 0 mins 2.16 secs\n",
      "Train Loss for batch 475/1057 @epoch5/5: 0.04781 in 0 mins 2.09 secs\n",
      "Train Loss for batch 500/1057 @epoch5/5: 0.07387 in 0 mins 2.13 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for batch 525/1057 @epoch5/5: 0.05788 in 0 mins 2.22 secs\n",
      "Train Loss for batch 550/1057 @epoch5/5: 0.0577 in 0 mins 2.11 secs\n",
      "Train Loss for batch 575/1057 @epoch5/5: 0.05351 in 0 mins 2.11 secs\n",
      "Train Loss for batch 600/1057 @epoch5/5: 0.05978 in 0 mins 2.13 secs\n",
      "Train Loss for batch 625/1057 @epoch5/5: 0.06678 in 0 mins 2.14 secs\n",
      "Train Loss for batch 650/1057 @epoch5/5: 0.06493 in 0 mins 2.3 secs\n",
      "Train Loss for batch 675/1057 @epoch5/5: 0.05934 in 0 mins 2.27 secs\n",
      "Train Loss for batch 700/1057 @epoch5/5: 0.06079 in 0 mins 2.21 secs\n",
      "Train Loss for batch 725/1057 @epoch5/5: 0.07162 in 0 mins 2.15 secs\n",
      "Train Loss for batch 750/1057 @epoch5/5: 0.06451 in 15 mins 50.34 secs\n",
      "Train Loss for batch 775/1057 @epoch5/5: 0.06387 in 0 mins 2.23 secs\n",
      "Train Loss for batch 800/1057 @epoch5/5: 0.06163 in 0 mins 2.24 secs\n",
      "Train Loss for batch 825/1057 @epoch5/5: 0.058 in 0 mins 2.09 secs\n",
      "Train Loss for batch 850/1057 @epoch5/5: 0.05768 in 0 mins 2.18 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for batch 875/1057 @epoch5/5: 0.05909 in 0 mins 2.11 secs\n",
      "Train Loss for batch 900/1057 @epoch5/5: 0.05182 in 0 mins 2.14 secs\n",
      "Train Loss for batch 925/1057 @epoch5/5: 0.05776 in 0 mins 2.1 secs\n",
      "Train Loss for batch 950/1057 @epoch5/5: 0.0565 in 0 mins 2.11 secs\n",
      "Train Loss for batch 975/1057 @epoch5/5: 0.0653 in 0 mins 2.11 secs\n",
      "Train Loss for batch 1000/1057 @epoch5/5: 0.05407 in 0 mins 2.09 secs\n",
      "Train Loss for batch 1025/1057 @epoch5/5: 0.05745 in 0 mins 2.14 secs\n",
      "Train Loss for batch 1050/1057 @epoch5/5: 0.05607 in 0 mins 2.11 secs\n",
      "VALIDATION\n",
      "Val Loss   for batch 025/265 @epoch5/5: 0.05935 in 0 mins 1.11 secs\n",
      "Val Loss   for batch 050/265 @epoch5/5: 0.06765 in 0 mins 1.11 secs\n",
      "Val Loss   for batch 075/265 @epoch5/5: 0.05564 in 0 mins 1.1 secs\n",
      "Val Loss   for batch 100/265 @epoch5/5: 0.05608 in 0 mins 1.2 secs\n",
      "Val Loss   for batch 125/265 @epoch5/5: 0.05975 in 0 mins 1.13 secs\n",
      "Val Loss   for batch 150/265 @epoch5/5: 0.05578 in 0 mins 1.11 secs\n",
      "Val Loss   for batch 175/265 @epoch5/5: 0.05576 in 0 mins 1.1 secs\n",
      "Val Loss   for batch 200/265 @epoch5/5: 0.05436 in 0 mins 1.11 secs\n",
      "Val Loss   for batch 225/265 @epoch5/5: 0.05656 in 0 mins 1.13 secs\n",
      "Val Loss   for batch 250/265 @epoch5/5: 0.05884 in 0 mins 1.13 secs\n",
      "\n",
      "NoFindingIndex:  10\n",
      "y_true.shape, y_probs.shape  (8449, 15) (8449, 15)\n",
      "\n",
      "class_roc_auc_list:  [0.7989185391913352, 0.9419043554718397, 0.7806151936839568, 0.9037423260779889, 0.8632322759548074, 0.8880160628265146, 0.8370327774583094, 0.8448318496538081, 0.7051894694381717, 0.831200758168488, 0.7915164493955369, 0.7578623365173206, 0.784882032824399, 0.72763502287366, 0.8697057452663008]\n",
      "\n",
      "useful_classes_roc_auc_list [0.7989185391913352, 0.9419043554718397, 0.7806151936839568, 0.9037423260779889, 0.8632322759548074, 0.8880160628265146, 0.8370327774583094, 0.8448318496538081, 0.7051894694381717, 0.831200758168488, 0.7578623365173206, 0.784882032824399, 0.72763502287366, 0.8697057452663008]\n",
      "\n",
      "checkpoint models/vit_base_1e-05_05.pth saved\n",
      "loss plots saved !!!\n",
      "\n",
      "TRAIN LOSS : 0.05866020937138393\n",
      "VAL   LOSS : 0.0577248231401908\n",
      "VAL ROC_AUC: 0.82391205324335\n",
      "\n",
      "Epoch 5/5 took 5 h 29 m\n",
      "total running time: 12 h 32m\n"
     ]
    }
   ],
   "source": [
    "train_model(vit_base, \"vit_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80d5b59d-fc1b-4e0a-8ed8-a02715ae57f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "we are working with \n",
      "Images shape: torch.Size([3, 224, 224]) and \n",
      "Target shape: torch.Size([15])\n",
      "\n",
      "checkpoint loaded: vit_base_1e-05_05.pth\n",
      "\n",
      "======= Testing... =======\n",
      "\n",
      "800/800 (100.00 %)\n",
      "NoFindingIndex:  10\n",
      "y_true.shape, y_probs.shape  (25596, 15) (25596, 15)\n",
      "\n",
      "class_roc_auc_list:  [0.7283401320814121, 0.8589345591653008, 0.7091878103025275, 0.8303291642337485, 0.794394348794234, 0.8324456340260294, 0.7813288856545456, 0.8506167212128395, 0.6256159109541888, 0.7491304578117551, 0.7092328939465433, 0.6817418389074441, 0.7367450204167982, 0.6614958674980239, 0.805954415984719]\n",
      "\n",
      "useful_classes_roc_auc_list [0.7283401320814121, 0.8589345591653008, 0.7091878103025275, 0.8303291642337485, 0.794394348794234, 0.8324456340260294, 0.7813288856545456, 0.8506167212128395, 0.6256159109541888, 0.7491304578117551, 0.6817418389074441, 0.7367450204167982, 0.6614958674980239, 0.805954415984719]\n",
      "test_roc_auc: 0.760447197645969 in 15 mins 10 secs\n",
      "total running time: 0 h 15m\n"
     ]
    }
   ],
   "source": [
    "test_model(\"vit_base\", \"vit_base_1e-05_05.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a791f4ae-4df3-4e32-8524-e9971fc8dd06",
   "metadata": {},
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2570832-5322-4a9d-bced-405349b778dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(weights=\"DEFAULT\")\n",
    "\n",
    "num_ftrs = vgg16.classifier[-1].in_features\n",
    "vgg16.classifier[-1] = nn.Linear(in_features=num_ftrs, out_features=len(XRayTrain_dataset.all_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f821c11f-3429-48fd-a2e6-068bf2508746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING THE MODEL FROM SCRATCH\n",
      "\n",
      "we are working with \n",
      "Images shape: torch.Size([3, 224, 224]) and \n",
      "Target shape: torch.Size([15])\n",
      "\n",
      "training from scratch\n",
      "\n",
      "> loss_fn: FocalLoss()\n",
      "> epochs_till_now: 0\n",
      "> batch_size: 32\n",
      "> stage: 1\n",
      "> lr: 1e-05\n",
      "\n",
      "======= Training after epoch #0... =======\n",
      "\n",
      "============ EPOCH 1/5 ============\n",
      "TRAINING\n",
      "Train Loss for batch 025/1056 @epoch1/5: 0.08661 in 0 mins 44.9 secs\n",
      "Train Loss for batch 050/1056 @epoch1/5: 0.07364 in 0 mins 51.36 secs\n",
      "Train Loss for batch 075/1056 @epoch1/5: 0.06935 in 0 mins 42.2 secs\n",
      "Train Loss for batch 100/1056 @epoch1/5: 0.08475 in 0 mins 41.41 secs\n",
      "Train Loss for batch 125/1056 @epoch1/5: 0.07611 in 0 mins 56.07 secs\n",
      "Train Loss for batch 150/1056 @epoch1/5: 0.05866 in 0 mins 52.96 secs\n",
      "Train Loss for batch 175/1056 @epoch1/5: 0.0771 in 0 mins 38.01 secs\n",
      "Train Loss for batch 200/1056 @epoch1/5: 0.07359 in 0 mins 44.79 secs\n",
      "Train Loss for batch 225/1056 @epoch1/5: 0.07062 in 1 mins 6.65 secs\n",
      "Train Loss for batch 250/1056 @epoch1/5: 0.07582 in 0 mins 40.28 secs\n",
      "Train Loss for batch 275/1056 @epoch1/5: 0.07885 in 1 mins 14.34 secs\n",
      "Train Loss for batch 300/1056 @epoch1/5: 0.06587 in 0 mins 52.94 secs\n",
      "Train Loss for batch 325/1056 @epoch1/5: 0.07163 in 1 mins 4.05 secs\n",
      "Train Loss for batch 350/1056 @epoch1/5: 0.07301 in 0 mins 49.16 secs\n",
      "Train Loss for batch 375/1056 @epoch1/5: 0.06725 in 0 mins 34.41 secs\n",
      "Train Loss for batch 400/1056 @epoch1/5: 0.08212 in 0 mins 41.3 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for batch 425/1056 @epoch1/5: 0.06686 in 0 mins 44.73 secs\n",
      "Train Loss for batch 450/1056 @epoch1/5: 0.06819 in 0 mins 50.05 secs\n",
      "Train Loss for batch 475/1056 @epoch1/5: 0.0666 in 0 mins 44.39 secs\n",
      "Train Loss for batch 500/1056 @epoch1/5: 0.06896 in 0 mins 43.43 secs\n",
      "Train Loss for batch 525/1056 @epoch1/5: 0.06345 in 1 mins 4.15 secs\n",
      "Train Loss for batch 550/1056 @epoch1/5: 0.07325 in 0 mins 32.13 secs\n",
      "Train Loss for batch 575/1056 @epoch1/5: 0.07377 in 0 mins 41.53 secs\n",
      "Train Loss for batch 600/1056 @epoch1/5: 0.06116 in 0 mins 50.95 secs\n",
      "Train Loss for batch 625/1056 @epoch1/5: 0.07141 in 0 mins 41.13 secs\n",
      "Train Loss for batch 650/1056 @epoch1/5: 0.07108 in 0 mins 36.46 secs\n",
      "Train Loss for batch 675/1056 @epoch1/5: 0.07433 in 0 mins 45.96 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for batch 700/1056 @epoch1/5: 0.0698 in 0 mins 37.77 secs\n",
      "Train Loss for batch 725/1056 @epoch1/5: 0.06767 in 0 mins 38.09 secs\n",
      "Train Loss for batch 750/1056 @epoch1/5: 0.06568 in 1 mins 4.07 secs\n",
      "Train Loss for batch 775/1056 @epoch1/5: 0.0765 in 0 mins 39.82 secs\n",
      "Train Loss for batch 800/1056 @epoch1/5: 0.07042 in 0 mins 38.84 secs\n",
      "Train Loss for batch 825/1056 @epoch1/5: 0.08157 in 0 mins 37.14 secs\n",
      "Train Loss for batch 850/1056 @epoch1/5: 0.07345 in 0 mins 36.58 secs\n",
      "Train Loss for batch 875/1056 @epoch1/5: 0.07357 in 0 mins 54.28 secs\n",
      "Train Loss for batch 900/1056 @epoch1/5: 0.06414 in 0 mins 46.34 secs\n",
      "Train Loss for batch 925/1056 @epoch1/5: 0.0604 in 0 mins 39.12 secs\n",
      "Train Loss for batch 950/1056 @epoch1/5: 0.06012 in 0 mins 32.1 secs\n",
      "Train Loss for batch 975/1056 @epoch1/5: 0.06689 in 0 mins 31.46 secs\n",
      "Train Loss for batch 1000/1056 @epoch1/5: 0.06236 in 0 mins 51.86 secs\n",
      "Train Loss for batch 1025/1056 @epoch1/5: 0.07011 in 0 mins 42.22 secs\n",
      "Train Loss for batch 1050/1056 @epoch1/5: 0.06599 in 0 mins 28.04 secs\n",
      "VALIDATION\n",
      "Val Loss   for batch 025/264 @epoch1/5: 0.06518 in 0 mins 8.06 secs\n",
      "Val Loss   for batch 050/264 @epoch1/5: 0.08344 in 0 mins 6.83 secs\n",
      "Val Loss   for batch 075/264 @epoch1/5: 0.06528 in 0 mins 8.61 secs\n",
      "Val Loss   for batch 100/264 @epoch1/5: 0.06013 in 0 mins 8.5 secs\n",
      "Val Loss   for batch 125/264 @epoch1/5: 0.05699 in 0 mins 5.89 secs\n",
      "Val Loss   for batch 150/264 @epoch1/5: 0.07576 in 0 mins 5.89 secs\n",
      "Val Loss   for batch 175/264 @epoch1/5: 0.06097 in 0 mins 6.72 secs\n",
      "Val Loss   for batch 200/264 @epoch1/5: 0.08006 in 0 mins 5.95 secs\n",
      "Val Loss   for batch 225/264 @epoch1/5: 0.06934 in 0 mins 5.77 secs\n",
      "Val Loss   for batch 250/264 @epoch1/5: 0.06341 in 0 mins 6.72 secs\n",
      "\n",
      "NoFindingIndex:  10\n",
      "y_true.shape, y_probs.shape  (8448, 15) (8448, 15)\n",
      "\n",
      "class_roc_auc_list:  [0.7355527353508573, 0.7999215424519741, 0.7232672554303239, 0.8199169057032903, 0.814808981685641, 0.7302817086800546, 0.7413022045321961, 0.6954689717455812, 0.6105577110902878, 0.6947862733005369, 0.7302245374556234, 0.661388891041359, 0.6752854593858133, 0.6024123979572504, 0.7033130684327732]\n",
      "\n",
      "useful_classes_roc_auc_list [0.7355527353508573, 0.7999215424519741, 0.7232672554303239, 0.8199169057032903, 0.814808981685641, 0.7302817086800546, 0.7413022045321961, 0.6954689717455812, 0.6105577110902878, 0.6947862733005369, 0.661388891041359, 0.6752854593858133, 0.6024123979572504, 0.7033130684327732]\n",
      "\n",
      "checkpoint models/vgg16_1e-05_01.pth saved\n",
      "loss plots saved !!!\n",
      "\n",
      "TRAIN LOSS : 0.07269991136454519\n",
      "VAL   LOSS : 0.06588168178374569\n",
      "VAL ROC_AUC: 0.71487600762771\n",
      "\n",
      "Epoch 1/5 took 14 h 19 m\n",
      "\n",
      "Sampling the huuuge training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 86524/86524 [00:02<00:00, 33475.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "self.all_classes_dict: {'No Finding': 10000, 'Atelectasis': 7709, 'Effusion': 8040, 'Nodule': 4416, 'Pleural_Thickening': 2131, 'Consolidation': 2655, 'Mass': 3838, 'Infiltration': 10005, 'Cardiomegaly': 1634, 'Pneumonia': 786, 'Edema': 1202, 'Emphysema': 1366, 'Pneumothorax': 2528, 'Fibrosis': 1171, 'Hernia': 141}\n",
      "\n",
      "-----Resampled Dataset Information-----\n",
      "num images in train_dataset   : 33795\n",
      "num images in val_dataset     : 8449\n",
      "---------------------------------------\n",
      "\n",
      "-----Resampled Batchloaders Information -----\n",
      "num batches in train_loader: 1057\n",
      "num batches in val_loader  : 265\n",
      "---------------------------------------------\n",
      "\n",
      "============ EPOCH 2/5 ============\n",
      "TRAINING\n",
      "Train Loss for batch 025/1057 @epoch2/5: 0.06106 in 0 mins 29.19 secs\n",
      "Train Loss for batch 050/1057 @epoch2/5: 0.08219 in 0 mins 47.61 secs\n",
      "Train Loss for batch 075/1057 @epoch2/5: 0.07099 in 0 mins 34.68 secs\n",
      "Train Loss for batch 100/1057 @epoch2/5: 0.05893 in 0 mins 39.33 secs\n",
      "Train Loss for batch 125/1057 @epoch2/5: 0.06663 in 0 mins 39.3 secs\n",
      "Train Loss for batch 150/1057 @epoch2/5: 0.07536 in 0 mins 34.49 secs\n",
      "Train Loss for batch 175/1057 @epoch2/5: 0.06805 in 0 mins 44.84 secs\n",
      "Train Loss for batch 200/1057 @epoch2/5: 0.06384 in 0 mins 35.75 secs\n",
      "Train Loss for batch 225/1057 @epoch2/5: 0.05855 in 0 mins 36.68 secs\n",
      "Train Loss for batch 250/1057 @epoch2/5: 0.06633 in 0 mins 27.29 secs\n",
      "Train Loss for batch 275/1057 @epoch2/5: 0.05883 in 0 mins 29.72 secs\n",
      "Train Loss for batch 300/1057 @epoch2/5: 0.06836 in 0 mins 40.33 secs\n",
      "Train Loss for batch 325/1057 @epoch2/5: 0.06384 in 0 mins 37.12 secs\n",
      "Train Loss for batch 350/1057 @epoch2/5: 0.07761 in 0 mins 31.44 secs\n",
      "Train Loss for batch 375/1057 @epoch2/5: 0.05311 in 0 mins 36.76 secs\n",
      "Train Loss for batch 400/1057 @epoch2/5: 0.06724 in 0 mins 26.53 secs\n",
      "Train Loss for batch 425/1057 @epoch2/5: 0.06957 in 0 mins 34.67 secs\n",
      "Train Loss for batch 450/1057 @epoch2/5: 0.08607 in 0 mins 28.08 secs\n",
      "Train Loss for batch 475/1057 @epoch2/5: 0.06425 in 0 mins 32.43 secs\n",
      "Train Loss for batch 500/1057 @epoch2/5: 0.06819 in 0 mins 41.29 secs\n",
      "Train Loss for batch 525/1057 @epoch2/5: 0.07443 in 0 mins 43.31 secs\n",
      "Train Loss for batch 550/1057 @epoch2/5: 0.0651 in 0 mins 33.64 secs\n",
      "Train Loss for batch 575/1057 @epoch2/5: 0.07679 in 0 mins 33.11 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for batch 600/1057 @epoch2/5: 0.06514 in 0 mins 28.76 secs\n",
      "Train Loss for batch 625/1057 @epoch2/5: 0.05438 in 0 mins 24.63 secs\n",
      "Train Loss for batch 650/1057 @epoch2/5: 0.06547 in 0 mins 32.02 secs\n",
      "Train Loss for batch 675/1057 @epoch2/5: 0.06805 in 0 mins 32.25 secs\n",
      "Train Loss for batch 700/1057 @epoch2/5: 0.07123 in 0 mins 33.01 secs\n",
      "Train Loss for batch 725/1057 @epoch2/5: 0.06575 in 0 mins 51.18 secs\n",
      "Train Loss for batch 750/1057 @epoch2/5: 0.05689 in 0 mins 31.89 secs\n",
      "Train Loss for batch 775/1057 @epoch2/5: 0.08006 in 0 mins 23.77 secs\n",
      "Train Loss for batch 800/1057 @epoch2/5: 0.06445 in 0 mins 31.1 secs\n",
      "Train Loss for batch 825/1057 @epoch2/5: 0.06137 in 0 mins 37.38 secs\n",
      "Train Loss for batch 850/1057 @epoch2/5: 0.06416 in 0 mins 45.08 secs\n",
      "Train Loss for batch 875/1057 @epoch2/5: 0.06393 in 0 mins 33.2 secs\n",
      "Train Loss for batch 900/1057 @epoch2/5: 0.06435 in 0 mins 23.95 secs\n",
      "Train Loss for batch 925/1057 @epoch2/5: 0.0714 in 0 mins 33.07 secs\n",
      "Train Loss for batch 950/1057 @epoch2/5: 0.06153 in 0 mins 48.16 secs\n",
      "Train Loss for batch 975/1057 @epoch2/5: 0.06613 in 0 mins 41.6 secs\n",
      "Train Loss for batch 1000/1057 @epoch2/5: 0.05502 in 0 mins 57.41 secs\n",
      "Train Loss for batch 1025/1057 @epoch2/5: 0.06472 in 0 mins 24.26 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for batch 1050/1057 @epoch2/5: 0.0732 in 0 mins 51.45 secs\n",
      "VALIDATION\n",
      "Val Loss   for batch 025/265 @epoch2/5: 0.06998 in 0 mins 4.02 secs\n",
      "Val Loss   for batch 050/265 @epoch2/5: 0.06666 in 0 mins 7.03 secs\n",
      "Val Loss   for batch 075/265 @epoch2/5: 0.06333 in 0 mins 3.74 secs\n",
      "Val Loss   for batch 100/265 @epoch2/5: 0.05464 in 0 mins 3.94 secs\n",
      "Val Loss   for batch 125/265 @epoch2/5: 0.0531 in 0 mins 4.01 secs\n",
      "Val Loss   for batch 150/265 @epoch2/5: 0.06771 in 0 mins 0.82 secs\n",
      "Val Loss   for batch 175/265 @epoch2/5: 0.0641 in 0 mins 0.82 secs\n",
      "Val Loss   for batch 200/265 @epoch2/5: 0.05712 in 0 mins 0.8 secs\n",
      "Val Loss   for batch 225/265 @epoch2/5: 0.06583 in 0 mins 0.83 secs\n",
      "Val Loss   for batch 250/265 @epoch2/5: 0.06285 in 0 mins 0.83 secs\n",
      "\n",
      "NoFindingIndex:  10\n",
      "y_true.shape, y_probs.shape  (8449, 15) (8449, 15)\n",
      "\n",
      "class_roc_auc_list:  [0.7549917665389188, 0.8594325991585189, 0.7199712123804529, 0.8778144314666194, 0.8386663278271917, 0.8380570436059346, 0.7805653186819107, 0.7392645950938606, 0.6644998058112124, 0.7294037090468126, 0.7590663934076521, 0.6979376277041264, 0.7325787923958529, 0.6603361738247725, 0.7891278759073556]\n",
      "\n",
      "useful_classes_roc_auc_list [0.7549917665389188, 0.8594325991585189, 0.7199712123804529, 0.8778144314666194, 0.8386663278271917, 0.8380570436059346, 0.7805653186819107, 0.7392645950938606, 0.6644998058112124, 0.7294037090468126, 0.6979376277041264, 0.7325787923958529, 0.6603361738247725, 0.7891278759073556]\n",
      "\n",
      "checkpoint models/vgg16_1e-05_02.pth saved\n",
      "loss plots saved !!!\n",
      "\n",
      "TRAIN LOSS : 0.06568439885067823\n",
      "VAL   LOSS : 0.06279693180420706\n",
      "VAL ROC_AUC: 0.7630462342459671\n",
      "\n",
      "Epoch 2/5 took 10 h 15 m\n",
      "\n",
      "Sampling the huuuge training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 86524/86524 [00:02<00:00, 33593.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "self.all_classes_dict: {'No Finding': 10000, 'Infiltration': 10006, 'Fibrosis': 1181, 'Consolidation': 2654, 'Pneumothorax': 2513, 'Effusion': 8015, 'Edema': 1218, 'Nodule': 4418, 'Pleural_Thickening': 2122, 'Atelectasis': 7688, 'Mass': 3818, 'Cardiomegaly': 1628, 'Emphysema': 1357, 'Pneumonia': 785, 'Hernia': 141}\n",
      "\n",
      "-----Resampled Dataset Information-----\n",
      "num images in train_dataset   : 33795\n",
      "num images in val_dataset     : 8449\n",
      "---------------------------------------\n",
      "\n",
      "-----Resampled Batchloaders Information -----\n",
      "num batches in train_loader: 1057\n",
      "num batches in val_loader  : 265\n",
      "---------------------------------------------\n",
      "\n",
      "============ EPOCH 3/5 ============\n",
      "TRAINING\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_model(vgg16, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvgg16\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 53\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, model_name, loss, epochs, lr)\u001b[0m\n\u001b[1;32m     50\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m p: p\u001b[38;5;241m.\u001b[39mrequires_grad, model\u001b[38;5;241m.\u001b[39mparameters()), lr \u001b[38;5;241m=\u001b[39m lr)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# make changes in the parameters of the following 'fit' function\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m fit(device, XRayTrain_dataset, train_loader, val_loader,    \n\u001b[1;32m     54\u001b[0m                                         test_loader, model, model_name, loss_fn, \n\u001b[1;32m     55\u001b[0m                                         optimizer, losses_dict,\n\u001b[1;32m     56\u001b[0m                                         epochs_till_now \u001b[38;5;241m=\u001b[39m epochs_till_now, epochs \u001b[38;5;241m=\u001b[39m epochs,\n\u001b[1;32m     57\u001b[0m                                         log_interval \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m, save_interval \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     58\u001b[0m                                         lr \u001b[38;5;241m=\u001b[39m lr, bs \u001b[38;5;241m=\u001b[39m batch_size,\n\u001b[1;32m     59\u001b[0m                                         test_only \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, )\n\u001b[1;32m     61\u001b[0m script_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m script_start_time\n\u001b[1;32m     62\u001b[0m m, s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdivmod\u001b[39m(script_time, \u001b[38;5;241m60\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/nih-x-ray/NIH-Chest-X-Rays-Multi-Label-Image-Classification-In-Pytorch/trainer.py:249\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(device, XRayTrain_dataset, train_loader, val_loader, test_loader, model, model_name, loss_fn, optimizer, losses_dict, epochs_till_now, epochs, log_interval, save_interval, lr, bs, test_only)\u001b[0m\n\u001b[1;32m    246\u001b[0m epoch_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRAINING\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 249\u001b[0m train_loss, mean_running_train_loss          \u001b[38;5;241m=\u001b[39m  train_epoch(device, train_loader, model, loss_fn, optimizer, epochs_till_now, final_epoch, log_interval)\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVALIDATION\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    251\u001b[0m val_loss, mean_running_val_loss, roc_auc     \u001b[38;5;241m=\u001b[39m  val_epoch(device, val_loader, model, loss_fn                             , epochs_till_now, final_epoch, log_interval)\n",
      "File \u001b[0;32m~/Desktop/nih-x-ray/NIH-Chest-X-Rays-Multi-Label-Image-Classification-In-Pytorch/trainer.py:125\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(device, train_loader, model, loss_fn, optimizer, epochs_till_now, final_epoch, log_interval)\u001b[0m\n\u001b[1;32m    121\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (img, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;66;03m# print(type(img), img.shape) # , np.unique(img))\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    126\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    128\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()    \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(vgg16, \"vgg16\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c82b38d8-e697-4c32-ae60-0914d6a21785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------test: epoch 1------\n",
      "\n",
      "we are working with \n",
      "Images shape: torch.Size([3, 224, 224]) and \n",
      "Target shape: torch.Size([15])\n",
      "\n",
      "checkpoint loaded: resnet50_1e-05_01.pth\n",
      "\n",
      "======= Testing... =======\n",
      "\n",
      "800/800 (100.00 %)\n",
      "NoFindingIndex:  10\n",
      "y_true.shape, y_probs.shape  (25596, 15) (25596, 15)\n",
      "\n",
      "class_roc_auc_list:  [0.7189187178896098, 0.762261119768623, 0.6890372931234429, 0.7953925990357427, 0.7796063423218341, 0.7746592001972684, 0.7548162705738264, 0.6546769164850992, 0.6504116244930731, 0.6760494645915358, 0.6984763393888749, 0.6668943565824553, 0.6864999182998907, 0.610570915950094, 0.7961622202442222]\n",
      "\n",
      "useful_classes_roc_auc_list [0.7189187178896098, 0.762261119768623, 0.6890372931234429, 0.7953925990357427, 0.7796063423218341, 0.7746592001972684, 0.7548162705738264, 0.6546769164850992, 0.6504116244930731, 0.6760494645915358, 0.6668943565824553, 0.6864999182998907, 0.610570915950094, 0.7961622202442222]\n",
      "test_roc_auc: 0.715425497111194 in 9 mins 29 secs\n",
      "total running time: 0 h 9m\n",
      "------test: epoch 2------\n",
      "\n",
      "we are working with \n",
      "Images shape: torch.Size([3, 224, 224]) and \n",
      "Target shape: torch.Size([15])\n",
      "\n",
      "checkpoint loaded: resnet50_1e-05_02.pth\n",
      "\n",
      "======= Testing... =======\n",
      "\n",
      "800/800 (100.00 %)\n",
      "NoFindingIndex:  10\n",
      "y_true.shape, y_probs.shape  (25596, 15) (25596, 15)\n",
      "\n",
      "class_roc_auc_list:  [0.722984854772802, 0.8116161136332717, 0.7031090287486723, 0.8189469636634323, 0.7943075388988103, 0.8455159942885048, 0.768874882538064, 0.7946833435132596, 0.6638851830767841, 0.7141619583256889, 0.701024188556493, 0.6897469681117689, 0.7068508126665332, 0.6644982229144203, 0.8235879103171331]\n",
      "\n",
      "useful_classes_roc_auc_list [0.722984854772802, 0.8116161136332717, 0.7031090287486723, 0.8189469636634323, 0.7943075388988103, 0.8455159942885048, 0.768874882538064, 0.7946833435132596, 0.6638851830767841, 0.7141619583256889, 0.6897469681117689, 0.7068508126665332, 0.6644982229144203, 0.8235879103171331]\n",
      "test_roc_auc: 0.7516264125335103 in 9 mins 17 secs\n",
      "total running time: 0 h 9m\n",
      "------test: epoch 3------\n",
      "\n",
      "we are working with \n",
      "Images shape: torch.Size([3, 224, 224]) and \n",
      "Target shape: torch.Size([15])\n",
      "\n",
      "checkpoint loaded: resnet50_1e-05_03.pth\n",
      "\n",
      "======= Testing... =======\n",
      "\n",
      "800/800 (100.00 %)\n",
      "NoFindingIndex:  10\n",
      "y_true.shape, y_probs.shape  (25596, 15) (25596, 15)\n",
      "\n",
      "class_roc_auc_list:  [0.7342085251598638, 0.8323720526696243, 0.696558773278156, 0.8240553138765615, 0.7970650975476022, 0.8607264289650063, 0.7796392154068033, 0.8079799987237106, 0.6469965480805301, 0.7244008367832273, 0.7057903041021389, 0.6962469382080307, 0.7144468476834825, 0.662283728559037, 0.8295719608454206]\n",
      "\n",
      "useful_classes_roc_auc_list [0.7342085251598638, 0.8323720526696243, 0.696558773278156, 0.8240553138765615, 0.7970650975476022, 0.8607264289650063, 0.7796392154068033, 0.8079799987237106, 0.6469965480805301, 0.7244008367832273, 0.6962469382080307, 0.7144468476834825, 0.662283728559037, 0.8295719608454206]\n",
      "test_roc_auc: 0.7576108761276469 in 9 mins 20 secs\n",
      "total running time: 0 h 9m\n",
      "------test: epoch 4------\n",
      "\n",
      "we are working with \n",
      "Images shape: torch.Size([3, 224, 224]) and \n",
      "Target shape: torch.Size([15])\n",
      "\n",
      "checkpoint loaded: resnet50_1e-05_04.pth\n",
      "\n",
      "======= Testing... =======\n",
      "\n",
      "800/800 (100.00 %)\n",
      "NoFindingIndex:  10\n",
      "y_true.shape, y_probs.shape  (25596, 15) (25596, 15)\n",
      "\n",
      "class_roc_auc_list:  [0.7213584314499757, 0.8247115690796912, 0.6929166430640105, 0.8166685910911926, 0.7882152355103811, 0.8609883607806637, 0.7706343104430456, 0.827374353878552, 0.6540976138899309, 0.7223324715954669, 0.7025533820647194, 0.70207852698529, 0.7055154174922099, 0.6606410531772937, 0.8303516635230759]\n",
      "\n",
      "useful_classes_roc_auc_list [0.7213584314499757, 0.8247115690796912, 0.6929166430640105, 0.8166685910911926, 0.7882152355103811, 0.8609883607806637, 0.7706343104430456, 0.827374353878552, 0.6540976138899309, 0.7223324715954669, 0.70207852698529, 0.7055154174922099, 0.6606410531772937, 0.8303516635230759]\n",
      "test_roc_auc: 0.7555631601400555 in 9 mins 21 secs\n",
      "total running time: 0 h 9m\n",
      "------test: epoch 5------\n",
      "\n",
      "we are working with \n",
      "Images shape: torch.Size([3, 224, 224]) and \n",
      "Target shape: torch.Size([15])\n",
      "\n",
      "checkpoint loaded: resnet50_1e-05_05.pth\n",
      "\n",
      "======= Testing... =======\n",
      "\n",
      "800/800 (100.00 %)\n",
      "NoFindingIndex:  10\n",
      "y_true.shape, y_probs.shape  (25596, 15) (25596, 15)\n",
      "\n",
      "class_roc_auc_list:  [0.715068159733321, 0.8317763860243287, 0.6807723553643712, 0.8192090286549367, 0.7875569096206302, 0.8586051173075546, 0.7716490627942258, 0.8370880548439736, 0.6483991160420525, 0.7230309983825862, 0.7076632816099293, 0.6843221061566516, 0.7107974986134953, 0.6627152371012439, 0.8176789116022511]\n",
      "\n",
      "useful_classes_roc_auc_list [0.715068159733321, 0.8317763860243287, 0.6807723553643712, 0.8192090286549367, 0.7875569096206302, 0.8586051173075546, 0.7716490627942258, 0.8370880548439736, 0.6483991160420525, 0.7230309983825862, 0.6843221061566516, 0.7107974986134953, 0.6627152371012439, 0.8176789116022511]\n",
      "test_roc_auc: 0.7534763530172588 in 9 mins 18 secs\n",
      "total running time: 0 h 9m\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):\n",
    "    print(f\"------test: epoch {i}------\")\n",
    "    test_model(\"resnet50\", f\"resnet50_1e-05_0{i}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5d8f674-304a-4bc9-8430-8c0c0224a098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------test: epoch 1------\n",
      "\n",
      "we are working with \n",
      "Images shape: torch.Size([3, 224, 224]) and \n",
      "Target shape: torch.Size([15])\n",
      "\n",
      "checkpoint loaded: vit_base_1e-05_01.pth\n",
      "\n",
      "======= Testing... =======\n",
      "\n",
      "800/800 (100.00 %)\n",
      "NoFindingIndex:  10\n",
      "y_true.shape, y_probs.shape  (25596, 15) (25596, 15)\n",
      "\n",
      "class_roc_auc_list:  [0.7315606805228217, 0.830098389499394, 0.7029371434912909, 0.8136356834318004, 0.7838216335693665, 0.7832738258350949, 0.7690119766633912, 0.8444504207196448, 0.6513337967735104, 0.7176907912008702, 0.6973975855751797, 0.6754647782410994, 0.7159947490103589, 0.6594201005845908, 0.7979335346769569]\n",
      "\n",
      "useful_classes_roc_auc_list [0.7315606805228217, 0.830098389499394, 0.7029371434912909, 0.8136356834318004, 0.7838216335693665, 0.7832738258350949, 0.7690119766633912, 0.8444504207196448, 0.6513337967735104, 0.7176907912008702, 0.6754647782410994, 0.7159947490103589, 0.6594201005845908, 0.7979335346769569]\n",
      "test_roc_auc: 0.7483305360157279 in 14 mins 24 secs\n",
      "total running time: 0 h 14m\n",
      "------test: epoch 2------\n",
      "\n",
      "we are working with \n",
      "Images shape: torch.Size([3, 224, 224]) and \n",
      "Target shape: torch.Size([15])\n",
      "\n",
      "checkpoint loaded: vit_base_1e-05_02.pth\n",
      "\n",
      "======= Testing... =======\n",
      "\n",
      "800/800 (100.00 %)\n",
      "NoFindingIndex:  10\n",
      "y_true.shape, y_probs.shape  (25596, 15) (25596, 15)\n",
      "\n",
      "class_roc_auc_list:  [0.7299838489847206, 0.854474572856709, 0.7136692104248328, 0.8208274076029741, 0.794163710184695, 0.8203082028270041, 0.7782796948570744, 0.8551311387235284, 0.6648154377373408, 0.7410903830668221, 0.7045968707648322, 0.6830048638359559, 0.7223496829796043, 0.6573237188308472, 0.814146256372511]\n",
      "\n",
      "useful_classes_roc_auc_list [0.7299838489847206, 0.854474572856709, 0.7136692104248328, 0.8208274076029741, 0.794163710184695, 0.8203082028270041, 0.7782796948570744, 0.8551311387235284, 0.6648154377373408, 0.7410903830668221, 0.6830048638359559, 0.7223496829796043, 0.6573237188308472, 0.814146256372511]\n",
      "test_roc_auc: 0.7606834378060443 in 14 mins 29 secs\n",
      "total running time: 0 h 14m\n",
      "------test: epoch 3------\n",
      "\n",
      "we are working with \n",
      "Images shape: torch.Size([3, 224, 224]) and \n",
      "Target shape: torch.Size([15])\n",
      "\n",
      "checkpoint loaded: vit_base_1e-05_03.pth\n",
      "\n",
      "======= Testing... =======\n",
      "\n",
      "800/800 (100.00 %)\n",
      "NoFindingIndex:  10\n",
      "y_true.shape, y_probs.shape  (25596, 15) (25596, 15)\n",
      "\n",
      "class_roc_auc_list:  [0.7301507446768808, 0.8586240062353917, 0.7060042029524924, 0.8300710430344413, 0.7950899199382372, 0.8252862328525674, 0.7755709323908054, 0.8480390726846745, 0.6653195893180175, 0.7546353833623628, 0.7093190453757822, 0.6872021175804707, 0.737560053694879, 0.664909944088092, 0.8222309885853006]\n",
      "\n",
      "useful_classes_roc_auc_list [0.7301507446768808, 0.8586240062353917, 0.7060042029524924, 0.8300710430344413, 0.7950899199382372, 0.8252862328525674, 0.7755709323908054, 0.8480390726846745, 0.6653195893180175, 0.7546353833623628, 0.6872021175804707, 0.737560053694879, 0.664909944088092, 0.8222309885853006]\n",
      "test_roc_auc: 0.7643353022424723 in 14 mins 36 secs\n",
      "total running time: 0 h 14m\n",
      "------test: epoch 4------\n",
      "\n",
      "we are working with \n",
      "Images shape: torch.Size([3, 224, 224]) and \n",
      "Target shape: torch.Size([15])\n",
      "\n",
      "checkpoint loaded: vit_base_1e-05_04.pth\n",
      "\n",
      "======= Testing... =======\n",
      "\n",
      "800/800 (100.00 %)\n",
      "NoFindingIndex:  10\n",
      "y_true.shape, y_probs.shape  (25596, 15) (25596, 15)\n",
      "\n",
      "class_roc_auc_list:  [0.7224096228669812, 0.8484604679373792, 0.7066001251317259, 0.8281900951658967, 0.792641596869795, 0.8309237224308363, 0.7766034553566983, 0.8499767533023985, 0.6524535234172542, 0.7424074463401698, 0.707529261114622, 0.6810480259176355, 0.7234027503401727, 0.6636143031734263, 0.822020085871449]\n",
      "\n",
      "useful_classes_roc_auc_list [0.7224096228669812, 0.8484604679373792, 0.7066001251317259, 0.8281900951658967, 0.792641596869795, 0.8309237224308363, 0.7766034553566983, 0.8499767533023985, 0.6524535234172542, 0.7424074463401698, 0.6810480259176355, 0.7234027503401727, 0.6636143031734263, 0.822020085871449]\n",
      "test_roc_auc: 0.7600537124372727 in 14 mins 42 secs\n",
      "total running time: 0 h 14m\n",
      "------test: epoch 5------\n",
      "\n",
      "we are working with \n",
      "Images shape: torch.Size([3, 224, 224]) and \n",
      "Target shape: torch.Size([15])\n",
      "\n",
      "checkpoint loaded: vit_base_1e-05_05.pth\n",
      "\n",
      "======= Testing... =======\n",
      "\n",
      "800/800 (100.00 %)\n",
      "NoFindingIndex:  10\n",
      "y_true.shape, y_probs.shape  (25596, 15) (25596, 15)\n",
      "\n",
      "class_roc_auc_list:  [0.7283401320814121, 0.8589345591653008, 0.7091878103025275, 0.8303291642337485, 0.794394348794234, 0.8324456340260294, 0.7813288856545456, 0.8506167212128395, 0.6256159109541888, 0.7491304578117551, 0.7092328939465433, 0.6817418389074441, 0.7367450204167982, 0.6614958674980239, 0.805954415984719]\n",
      "\n",
      "useful_classes_roc_auc_list [0.7283401320814121, 0.8589345591653008, 0.7091878103025275, 0.8303291642337485, 0.794394348794234, 0.8324456340260294, 0.7813288856545456, 0.8506167212128395, 0.6256159109541888, 0.7491304578117551, 0.6817418389074441, 0.7367450204167982, 0.6614958674980239, 0.805954415984719]\n",
      "test_roc_auc: 0.760447197645969 in 14 mins 32 secs\n",
      "total running time: 0 h 14m\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):\n",
    "    print(f\"------test: epoch {i}------\")\n",
    "    test_model(\"vit\", f\"vit_base_1e-05_0{i}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6e92b2e-3fcc-4b85-b37a-6bef34e994b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------test: epoch 1------\n",
      "\n",
      "we are working with \n",
      "Images shape: torch.Size([3, 224, 224]) and \n",
      "Target shape: torch.Size([15])\n",
      "\n",
      "checkpoint loaded: vgg16_1e-05_01.pth\n",
      "\n",
      "======= Testing... =======\n",
      "\n",
      "800/800 (100.00 %)\n",
      "NoFindingIndex:  10\n",
      "y_true.shape, y_probs.shape  (25596, 15) (25596, 15)\n",
      "\n",
      "class_roc_auc_list:  [0.704740004375392, 0.7726988828828527, 0.6882666707442789, 0.7711994715318455, 0.7669718087722729, 0.7048018169368062, 0.7722097736553606, 0.7190365383388184, 0.6362165213959958, 0.6516461017988067, 0.6966797332621566, 0.6788396856095477, 0.7073846988199799, 0.590438059960044, 0.7629467405397529]\n",
      "\n",
      "useful_classes_roc_auc_list [0.704740004375392, 0.7726988828828527, 0.6882666707442789, 0.7711994715318455, 0.7669718087722729, 0.7048018169368062, 0.7722097736553606, 0.7190365383388184, 0.6362165213959958, 0.6516461017988067, 0.6788396856095477, 0.7073846988199799, 0.590438059960044, 0.7629467405397529]\n",
      "test_roc_auc: 0.7090997696686968 in 14 mins 16 secs\n",
      "total running time: 0 h 14m\n",
      "------test: epoch 2------\n",
      "\n",
      "we are working with \n",
      "Images shape: torch.Size([3, 224, 224]) and \n",
      "Target shape: torch.Size([15])\n",
      "\n",
      "checkpoint loaded: vgg16_1e-05_02.pth\n",
      "\n",
      "======= Testing... =======\n",
      "\n",
      "800/800 (100.00 %)\n",
      "NoFindingIndex:  10\n",
      "y_true.shape, y_probs.shape  (25596, 15) (25596, 15)\n",
      "\n",
      "class_roc_auc_list:  [0.7236242799574181, 0.836349876234598, 0.7033929556699835, 0.8003076377013388, 0.7934438386270435, 0.8120396333641615, 0.7625369859484232, 0.7999831347487989, 0.6689636301123972, 0.6939739248651068, 0.7048350656908273, 0.7036899876501546, 0.721999590765995, 0.6164656809678973, 0.8224948603866907]\n",
      "\n",
      "useful_classes_roc_auc_list [0.7236242799574181, 0.836349876234598, 0.7033929556699835, 0.8003076377013388, 0.7934438386270435, 0.8120396333641615, 0.7625369859484232, 0.7999831347487989, 0.6689636301123972, 0.6939739248651068, 0.7036899876501546, 0.721999590765995, 0.6164656809678973, 0.8224948603866907]\n",
      "test_roc_auc: 0.7470904297857147 in 96 mins 58 secs\n",
      "total running time: 1 h 36m\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,3):\n",
    "    print(f\"------test: epoch {i}------\")\n",
    "    test_model(\"vgg16\", f\"vgg16_1e-05_0{i}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33eb9fac-a3a3-4d5c-b7cd-bc2fe4b1c808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.538767, 138.357544, 85.810191)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(resnet50), count_parameters(vgg16), count_parameters(vit_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd41752-a69c-469e-b321-c6380d0ad7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypytorch",
   "language": "python",
   "name": "mypytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
